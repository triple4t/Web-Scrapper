We read every piece of feedback, and take your input very seriously.

            To see all available qualifiers, see our documentation.
          

        üöÄü§ñ Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper
      










Crawl4AI is the #1 trending GitHub repository, actively maintained by a vibrant community. It delivers blazing-fast, AI-ready web crawling tailored for LLMs, AI agents, and data pipelines. Open source, flexible, and built for real-time performance, Crawl4AI empowers developers with unmatched speed, precision, and deployment ease.
‚ú® Check out latest update v0.4.3bx
üéâ Version 0.4.3bx is out! This release brings exciting new features like a Memory Dispatcher System, Streaming Support, LLM-Powered Markdown Generation, Schema Generation, and Robots.txt Compliance! Read the release notes ‚Üí
My journey with computers started in childhood when my dad, a computer scientist, introduced me to an Amstrad computer. Those early days sparked a fascination with technology, leading me to pursue computer science and specialize in NLP during my postgraduate studies. It was during this time that I first delved into web crawling, building tools to help researchers organize papers and extract information from publications a challenging yet rewarding experience that honed my skills in data extraction.
Fast forward to 2023, I was working on a tool for a project and needed a crawler to convert a webpage into markdown. While exploring solutions, I found one that claimed to be open-source but required creating an account and generating an API token. Worse, it turned out to be a SaaS model charging $16, and its quality didn‚Äôt meet my standards. Frustrated, I realized this was a deeper problem. That frustration turned into turbo anger mode, and I decided to build my own solution. In just a few days, I created Crawl4AI. To my surprise, it went viral, earning thousands of GitHub stars and resonating with a global community.
I made Crawl4AI open-source for two reasons. First, it‚Äôs my way of giving back to the open-source community that has supported me throughout my career. Second, I believe data should be accessible to everyone, not locked behind paywalls or monopolized by a few. Open access to data lays the foundation for the democratization of AI, a vision where individuals can train their own models and take ownership of their information. This library is the first step in a larger journey to create the best open-source data extraction and generation tool the world has ever seen, built collaboratively by a passionate community.
Thank you to everyone who has supported this project, used it, and shared feedback. Your encouragement motivates me to dream even bigger. Join us, file issues, submit PRs, or spread the word. Together, we can build a tool that truly empowers people to access their own data and reshape the future of AI.
If you encounter any browser-related issues, you can install them manually:
‚ú® Play around with this 
‚ú® Visit our Documentation Website
Crawl4AI offers flexible installation options to suit various use cases. You can install it as a Python package or use Docker.
Choose the installation option that best fits your needs:
For basic web crawling and scraping tasks:
By default, this will install the asynchronous version of Crawl4AI, using Playwright for web crawling.
üëâ Note: When you install Crawl4AI, the crawl4ai-setup should automatically install and set up Playwright. However, if you encounter any Playwright-related errors, you can manually install it using one of these methods:
Through the command line:
If the above doesn't work, try this more specific command:
This second method has proven to be more reliable in some cases.
The sync version is deprecated and will be removed in future versions. If you need the synchronous version using Selenium:
For contributors who plan to modify the source code:
Install optional features:
üöÄ Major Changes Coming! We're developing a completely new Docker implementation that will make deployment even more efficient and seamless. The current Docker setup is being deprecated in favor of this new solution.
The existing Docker implementation is being deprecated and will be replaced soon. If you still need to use Docker with the current version:
Our new Docker implementation will bring:
Stay connected with our GitHub repository for updates!
Run a quick test (works for both Docker options):
For more examples, see our Docker Examples. For advanced configuration, environment variables, and usage examples, see our Docker Deployment Guide.
You can check the project structure in the directory https://github.com/unclecode/crawl4ai/docs/examples. Over there, you can find a variety of examples; here, some popular examples are shared.
Read the full details in our 0.4.3bx Release Notes.
Crawl4AI follows standard Python version numbering conventions (PEP 440) to help users understand the stability and features of each release.
Our version numbers follow this pattern: MAJOR.MINOR.PATCH (e.g., 0.4.3)
We use different suffixes to indicate development stages:
Regular installation (stable version):
Install pre-release versions:
Install specific version:
We use pre-releases to:
For production environments, we recommend using the stable version. For testing new features, you can opt-in to pre-releases using the --pre flag.
üö® Documentation Update Alert: We're undertaking a major documentation overhaul next week to reflect recent updates and improvements. Stay tuned for a more comprehensive and up-to-date guide!
For current documentation, including installation instructions, advanced features, and API reference, visit our Documentation Website.
To check our development plans and upcoming features, visit our Roadmap.
We welcome contributions from the open-source community. Check out our contribution guidelines for more information.
Crawl4AI is released under the Apache 2.0 License.
For questions, suggestions, or feedback, feel free to reach out:
Happy Crawling! üï∏Ô∏èüöÄ
Our mission is to unlock the value of personal and enterprise data by transforming digital footprints into structured, tradeable assets. Crawl4AI empowers individuals and organizations with open-source tools to extract and structure data, fostering a shared data economy.
We envision a future where AI is powered by real human knowledge, ensuring data creators directly benefit from their contributions. By democratizing data and enabling ethical sharing, we are laying the foundation for authentic AI advancement.
For more details, see our full mission statement.


        üöÄü§ñ Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper
      